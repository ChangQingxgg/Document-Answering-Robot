{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPf5BfhLRiduWSbl5e0TBx2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChangQingxgg/Document-Answering-Robot/blob/main/%E5%9B%BD%E5%86%85%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BB%BA%E7%AB%8B%E6%95%B0%E6%8D%AE%E5%BA%93%EF%BC%88%E6%9C%80%E7%BB%88%E7%89%88%EF%BC%89.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "!pip install datasets\n",
        "!pip install openai\n",
        "!pip install zhipuai"
      ],
      "metadata": {
        "id": "wI4TWobfkpgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Udq-srtDklOn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "from openai import OpenAI\n",
        "from zhipuai import ZhipuAI\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# API 密钥（请替换为你的实际 API 密钥）\n",
        "DEEPSEEK_API_KEY = \"sk-5bb4dcdbbbcb4d00a7a86c394b48f8cd\"\n",
        "ZHIPUAI_API_KEY = \"027ca123cc5f4ced99d7a7d257d68531.9OT5hZQLmCOSKpjG\"\n",
        "TONGYI_API_KEY = \"sk-7e39c80d2a2b4b049b90f534ef236062\"\n",
        "\n",
        "# 初始化客户端\n",
        "deepseek_client = OpenAI(api_key=DEEPSEEK_API_KEY, base_url=\"https://api.deepseek.com\")\n",
        "zhipuai_client = ZhipuAI(api_key=ZHIPUAI_API_KEY)\n",
        "tongyi_client = OpenAI(api_key=TONGYI_API_KEY, base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\")\n",
        "\n",
        "# 系统提示词，适用于所有模型\n",
        "system_prompt = \"\"\"你是一位医学专家，拥有丰富的临床推理、诊断和治疗计划方面的先进知识。在回答之前，请仔细思考这个问题，建立一个循序渐进的思维链，以确保回答既合乎逻辑又准确无误。\"\"\"\n",
        "\n",
        "# DeepSeek 模型生成回答\n",
        "def generate_deepseek_response(question):\n",
        "    try:\n",
        "        response = deepseek_client.chat.completions.create(\n",
        "            model=\"deepseek-chat\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": f\"请回答以下医学问题: {question}\"}\n",
        "            ],\n",
        "            max_tokens=2048,\n",
        "            temperature=0.7,\n",
        "            stream=False\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating DeepSeek response: {e}\")\n",
        "        return \"Error: Unable to generate response.\"\n",
        "\n",
        "# 智谱清言模型生成回答\n",
        "def generate_zhipuai_response(question):\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": f\"请回答以下医学问题: {question}\"}\n",
        "    ]\n",
        "    try:\n",
        "        response = zhipuai_client.chat.completions.create(\n",
        "            model=\"glm-4-plus\",\n",
        "            messages=messages,\n",
        "            max_tokens=2048,\n",
        "            temperature=0.7\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating ZhipuAI response: {e}\")\n",
        "        return \"Error: Unable to generate response.\"\n",
        "\n",
        "# 通义千问模型生成回答\n",
        "def generate_tongyi_response(question):\n",
        "    try:\n",
        "        completion = tongyi_client.chat.completions.create(\n",
        "            model=\"qwen-plus\",\n",
        "            messages=[\n",
        "                {'role': 'system', 'content': system_prompt},\n",
        "                {'role': 'user', 'content': f\"请回答以下医学问题: {question}\"}\n",
        "            ],\n",
        "            max_tokens=2048,\n",
        "            temperature=0.7\n",
        "        )\n",
        "        return completion.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating Tongyi response: {e}\")\n",
        "        return \"Error: Unable to generate response.\"\n",
        "\n",
        "# 批量处理函数，生成三个模型的回答\n",
        "def add_generated_responses(batch):\n",
        "    questions = batch[\"Question\"]\n",
        "    deepseek_responses = [generate_deepseek_response(q) for q in questions]\n",
        "    zhipuai_responses = [generate_zhipuai_response(q) for q in questions]\n",
        "    tongyi_responses = [generate_tongyi_response(q) for q in questions]\n",
        "    return {\n",
        "        \"deepseek_response\": deepseek_responses,\n",
        "        \"zhipuai_response\": zhipuai_responses,\n",
        "        \"tongyi_response\": tongyi_responses\n",
        "    }\n",
        "\n",
        "# 加载医疗数据集\n",
        "dataset = load_dataset(\"FreedomIntelligence/medical-o1-reasoning-SFT\", \"zh\", split=\"train[0:20]\", trust_remote_code=True)\n",
        "\n",
        "# 应用映射函数，添加三个模型的生成回答\n",
        "dataset = dataset.map(add_generated_responses, batched=True, batch_size=8)\n",
        "\n",
        "# 取前 50 个样本作为演示\n",
        "dataset_subset = dataset.take(20)\n",
        "\n",
        "# 收集数据到列表中\n",
        "data = []\n",
        "for example in dataset_subset:\n",
        "    data.append({\n",
        "        \"question\": example[\"Question\"],\n",
        "        \"context\": example[\"Response\"],\n",
        "        \"deepseek_response\": example[\"deepseek_response\"],\n",
        "        \"zhipuai_response\": example[\"zhipuai_response\"],\n",
        "        \"tongyi_response\": example[\"tongyi_response\"]\n",
        "    })\n",
        "\n",
        "# 创建 Pandas DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# 保存 DataFrame 到 CSV 文件\n",
        "df.to_csv(\"/content/drive/MyDrive/medical_responses_qwen.csv\", index=False)\n",
        "print(\"数据库已保存至 'medical_responses.csv'\")"
      ]
    }
  ]
}