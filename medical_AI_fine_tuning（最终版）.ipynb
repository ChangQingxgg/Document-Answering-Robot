{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOWMOHucelCTaIMVWPCJA2D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChangQingxgg/Document-Answering-Robot/blob/main/medical_AI_fine_tuning%EF%BC%88%E6%9C%80%E7%BB%88%E7%89%88%EF%BC%89.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#本代码用于实现医学垂直领域微调模型。所使用的数据库为\"FreedomIntelligence/medical-o1-reasoning-SFT\"，使用的基础模型为\"unsloth/DeepSeek-R1-Distill-Llama-8B\"，使用的微调方法为LoRA微调。\n",
        "\n",
        "!pip install unsloth\n",
        "# Also get the latest nightly Unsloth!\n",
        "!pip install --force-reinstall --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git\n",
        "\n",
        "!pip install kaggle\n",
        "!pip install huggingface_hub      #一些导入\n",
        "!pip install wandb\n",
        "!pip install trl\n",
        "!pip install datasets\n",
        "!pip install transformers\n"
      ],
      "metadata": {
        "id": "lHPBAMKMu3E9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade triton\n",
        "!pip install --upgrade torch"
      ],
      "metadata": {
        "id": "La6tIj8SVnHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rB06M9BvtdbV"
      },
      "outputs": [],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 2048\n",
        "dtype = None\n",
        "load_in_4bit = True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#登录huggingface\n",
        "from huggingface_hub import login\n",
        "import os\n",
        "\n",
        "# Assuming your Hugging Face token is stored in the environment variable HUGGINGFACE_TOKEN\n",
        "hf_token = os.environ.get(\"HUGGINGFACE_TOKEN\")\n",
        "\n",
        "if hf_token is None:\n",
        "    # If token not found in environment variable, prompt user for input\n",
        "    hf_token = input(\"Please enter your Hugging Face token: \")\n",
        "\n",
        "login(hf_token)      #输入huggingface的token，登录huggingface，方便后续上传训练好的模型"
      ],
      "metadata": {
        "id": "wLxD3n_RtryZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "#登录wandb账户，建立项目，检测训练数据如训练损失、准确率等，并可视化结果，将结果上传到wandb账户中\n",
        "wandb.login(key=\"6b57ec8104d7625e887d4b78d700370b814189a1\")\n",
        "run = wandb.init(\n",
        "    project='my fint-tune on deepseek r1 with medical data',\n",
        "    job_type=\"training\",\n",
        "    anonymous=\"allow\"\n",
        ")"
      ],
      "metadata": {
        "id": "dxIQUhPotv5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#加载模型\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/DeepSeek-R1-Distill-Llama-8B\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        ")"
      ],
      "metadata": {
        "id": "7bXxsbX6YQpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prompt工程\n",
        "prompt_style = \"\"\"以下是一个描述任务的指令，配有一个提供进一步背景信息的输入。\n",
        "请撰写一个恰当完成请求的回复。\n",
        "在回答之前，请仔细思考问题，并构建一个严谨、周密的逐步推理链（Chain of Thoughts），以确保您的回答逻辑清晰且准确无误。\n",
        "\n",
        "### 系统设定：\n",
        "你是一位具有丰富临床经验的医疗专家，精通临床诊断推理、疾病诊断和治疗方案制定。\n",
        "请回答以下医学问题。\n",
        "\n",
        "### 问题：\n",
        "{}\n",
        "\n",
        "### 回答：\n",
        "<思考过程>{}"
      ],
      "metadata": {
        "id": "NjCpscZut0OW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#训练环节\n",
        "\n",
        "#LoRA微调的参数设计\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r=16,\n",
        "    target_modules=[\n",
        "        \"q_proj\",\n",
        "        \"k_proj\",\n",
        "        \"v_proj\",\n",
        "        \"o_proj\",\n",
        "        \"gate_proj\",\n",
        "        \"up_proj\",\n",
        "        \"down_proj\",\n",
        "    ],\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0,\n",
        "    bias=\"none\",\n",
        "    use_gradient_checkpointing=\"unsloth\",  # True or \"unsloth\" for very long context\n",
        "    random_state=3407,\n",
        "    use_rslora=False,\n",
        "    loftq_config=None,\n",
        ")"
      ],
      "metadata": {
        "id": "bCFi6kEFt5QU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_prompt_style = \"\"\"以下是一个描述任务的指令，配有一个提供进一步背景信息的输入。\n",
        "请撰写一个恰当完成请求的回复。\n",
        "在回答之前，请仔细思考问题，并构建一个严谨、周密的逐步推理链（Chain of Thoughts），以确保您的回答逻辑清晰且准确无误。\n",
        "\n",
        "### 系统设定：\n",
        "你是一位具有丰富临床经验的医疗专家，精通临床诊断推理、疾病诊断和治疗方案制定。\n",
        "请回答以下医学问题。\n",
        "\n",
        "### 问题：\n",
        "{}\n",
        "\n",
        "### 回答：\n",
        "<思考过程>{}\"\"\""
      ],
      "metadata": {
        "id": "Q4TwC9Ast8FV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#数据集载入及格式化\n",
        "EOS_TOKEN = tokenizer.eos_token  # Must add EOS_TOKEN\n",
        "\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "    inputs = examples[\"Question\"]\n",
        "    cots = examples[\"Complex_CoT\"]\n",
        "    outputs = examples[\"Response\"]\n",
        "    texts = []\n",
        "    for input, cot, output in zip(inputs, cots, outputs):\n",
        "        text = train_prompt_style.format(input, cot, output) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return {\n",
        "        \"text\": texts,\n",
        "    }"
      ],
      "metadata": {
        "id": "mg5xEKGdt-Ld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"FreedomIntelligence/medical-o1-reasoning-SFT\",\"zh\", split = \"train[0:5000]\",trust_remote_code=True)\n",
        "dataset = dataset.map(formatting_prompts_func, batched = True,)\n",
        "dataset[\"text\"][0]"
      ],
      "metadata": {
        "id": "5R3KaT-kt_7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#训练模型的参数设置\n",
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from unsloth import is_bfloat16_supported\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=dataset,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    dataset_num_proc=2,\n",
        "    args=TrainingArguments(\n",
        "        per_device_train_batch_size=2,\n",
        "        gradient_accumulation_steps=4,\n",
        "        # Use num_train_epochs = 1, warmup_ratio for full training runs!\n",
        "        warmup_steps=5,\n",
        "        max_steps=60,\n",
        "        learning_rate=2e-4,\n",
        "        fp16=not is_bfloat16_supported(),\n",
        "        bf16=is_bfloat16_supported(),\n",
        "        logging_steps=5,\n",
        "        optim=\"adamw_8bit\",\n",
        "        weight_decay=0.01,\n",
        "        lr_scheduler_type=\"linear\",\n",
        "        seed=3407,\n",
        "        output_dir=\"outputs\",\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "IZMq7LQkuGGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_stats = trainer.train()"
      ],
      "metadata": {
        "id": "3FeH9MmkuI4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 保存微调模型\n",
        "import wandb\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "asPVcmxbuQ6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import create_repo\n",
        "#设置仓库名称\n",
        "repo_name = \"ChangQingxgg/deepseek_8b_medical_trained_final\"\n",
        "huggingface_token=\"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\"\n",
        "\n",
        "#创建仓库\n",
        "create_repo(repo_name, token=huggingface_token, exist_ok=True)\n",
        "\n",
        "# 上传模型和分词器\n",
        "model.push_to_hub(repo_name, token=huggingface_token)\n",
        "tokenizer.push_to_hub(repo_name, token=huggingface_token)"
      ],
      "metadata": {
        "id": "jgFzZKxxiDwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model_online = \"ChangQingxgg/DeepSeek-R1-Medical-COT\"\n",
        "new_model_local = \"DeepSeek-R1-Medical-COT\"\n",
        "model.save_pretrained(new_model_local) # Local saving\n",
        "tokenizer.save_pretrained(new_model_local)"
      ],
      "metadata": {
        "id": "I4muWYo9ua-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.push_to_hub(new_model_online) # Online saving\n",
        "tokenizer.push_to_hub(new_model_online) # Online saving\n",
        "#161"
      ],
      "metadata": {
        "id": "nJX5lS-Hucrf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}