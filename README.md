# Document-Answering-Robot

### 团队成员 许明乙   詹力闻   张志豪

## 第一周

**需求分析**  
1.功能指标：完成一个能够根据给定内容（wiki上关于deepin系统相关的知识）回答问题的中文聊天机器人，并在博客中记录开发过程中的心得体会，将博客投递到planet.deepin.org

2.性能指标：模型经过训练后需使得回答和问题有80%以上概率的相关性

## 第二周

1.初步了解了pytorch框架以及部分python指令，为后续编程打基础。

2.阅读了部分参考文献，了解了参考文档的形式、问答系统的定义、特点、分类等。查看了部分示例的问答系统，对问答系统的形式有了初步的了解。

## 第三周

1.查阅文献，进一步深入了解问答系统的相关知识。结合现有技术框架，形成了包含数据预处理、模型微调与评估优化的全流程技术方案，已完成初步的路径设计。

2.针对目标领域知识获取需求，已成功利用网络爬虫系统完成指定知识源的原始数据采集，然而在面对数据处理问题时却一筹莫展。为解决数据格式化、加标签等难题，经查阅文献，拟采用**Argilla**开源框架实施数据预处理工程。

3.项目采用三阶段递进式技术路线：

* 数据处理阶段：基于Argilla对参考文档进行处理，实现数据的预处理工作，建立高质量数据库，用于训练与评估。
* 模型训练阶段：使用数据库进行大模型微调训练，并不断评估调优。
* 评估优化阶段：建立包含exact-match、F1-score及语义相似度的多维度评估体系，设计动态参数调优策略
  目标设定为在保留测试集上实现问答相关性得分≥80%，达到项目要求。

4.建立起了工程文件，计划后续进一步完善

## 第四周

1.学习了huggingface社区中Llm course的部分章节，对大语言模型以及如何对大语言模型进行微调有了进一步的了解，掌握了完成项目需要用到的部分知识。

2.数据库准备方面，掌握了使用tokenizer等工具处理文本使之成为模型可以处理的batchs的方法；掌握了对数据添加标签、格式化的方法。但是对如何将给定数据文档转化为数据库并进行预处理、使之符合问答模型需要的形式这个问题仍一筹莫展。

3.大模型微调方面：学习了常见的聊天模板格式如Llama 2、Mistral 等，并且了解了常见格式之间的主要差异以及transformers 库如何处理这些差异。



## 第五周

1.进行了AI大模型微调的实践。利用huggingface上的"FreedomIntelligence/medical-o1-reasoning-SFT"数据集，使用Lora低秩微调方法对deepseek-r1-8b进行了微调，并保存了微调后的模型，积累了大模型微调的经验。

2.进一步查阅资料，发现RAG技术可以用于本项目，计划后续使用RAG技术对大模型进行进一步的优化，提高问答正确率。

3.学习了一系列大模型文本评价方法，最终实现了LLM大模型评估方法，即使用其他大模型对本模型的问答质量进行评估，可以不仅仅局限于正确率，而是多方位多层次地进行全面的评估，如文本生成质量、幻觉率等等。

4.提交了相关的colab代码（由于本地算力资源较为匮乏，故使用colab实现）



## 第六周

1.继续尝试使用爬虫爬取目标网页内容并生成知识库。但是目标网址的侧边栏网址一直难以获取，在多次尝试无果后决定手动输入剩下的所需网址，并对数据进行清洗、格式化。数据库初始阶段完成。

2.初步了解了RAG技术。

3.学习了Hugging Face的PETF库。



## 第七周

1.了解了RAG模型的工作原理，用BERT和gpt2实现了简单的检索与生成模块，但不知为什么生成内容时总会生成些乱七八糟的东西。

## 第八周

1.成功落地了大模型评估法的代码，实现了对国内三大模型的自定义评估指标的评估工作，为后续评估问答机器人铺平了道路。

2.实现了调用大模型对问题进行回答，构建问题-答案-大模型回答格式的数据库。

## 第九周

1.尝试了对deepin.wiki.org进行处理形成检索索引并借助大模型进行回答的尝试，但是效果并不理想。检查后发现检索系统成功实现了对文档进行处理，但是问答却不尽人意。问题似乎出在了大模型能力以及针对问题的自然语言处理上，期待后续能够解决。

## 第十周

1.针对模型能力，选择先使用调用deepseekAPI的方式来获得足够的大模型能力，首先验证我们的方法可行，再进行后续模型的调整。为提高检索效率与检索准确度，对文档进行分块和重叠处理等。为提高检索准度，采用改进的检索方法。但是效果仍不理想。且执行过程中出现RAM耗尽的问题，算力无法支持我们的方法。

## 第二学期

## 第一周

1.重新审视了项目代码，发现由于colab以及huggingface的变化，部分.ipynb文件无法显示，且部分测试时使用的数据库也已经被删除。但是这些代码的确是前几周的主要工作成果，故仍将原代码上传。

2.上学期最终的成果为实现了一个简单的文档问答机器人。它能够实现检索功能，但是面对较为复杂的问题时表现不好；学习了微调模型相关的知识并进行了实践尝试，但在使用微调模型进行文档问答时出现效果不佳、RAM不足等问题；实现了对大模型性能进行评估的方法，便于最终评估文档问答机器人的性能。

3.继续尝试对文档问答机器人进行优化处理。

## 第二周

1、深入分析了之前遇到的问题，特别是检索效果不好和RAM不足的问题，决定放弃微调的方法，采用RAG架构。

2、搭建了基础的检索系统框架，初步实现了FAISS向量索引和BM25关键词索引的构建，为后续的混合检索做准备。

3、解决了之前遇到的RAM不足问题，通过优化数据处理流程和分批处理文档，使得系统能够在Colab环境中稳定运行。

## 第三周

1、我们采用稠密检索和稀疏检索结合的策略，提升了检索精度。经过测试，该问答机器人在测试集上达到了93.33%的准确率，达到了项目设定的80%的目标，成功实现了基于RAG的文档问答机器人。

2、该机器人包含以下的四个核心模块：

文档预处理模块：获取Deepin Wiki文档，划分片段，构建索引

检索模块：先通过混合检索初步筛选文档，再使用reranker模型提升精度

生成模块：调用deepseek的API，生成回答

评估模块：进行自动化的质量评估和错误分析

3、提交了完整的项目代码、赛题报告等资料，项目圆满完成。

